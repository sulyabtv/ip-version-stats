from argparse import ArgumentParser
from datetime import datetime
import re
from copy import deepcopy
from typing import Optional
import pickle
from tqdm import tqdm

from socket import gethostbyaddr
from ipaddress import ip_address
from pyasn import pyasn

def get_parser() -> ArgumentParser:
    parser = ArgumentParser( description="IP-Version-Stats: A tool to monitor network traffic and obtain IPv4 vs IPv6 traffic statistics." )

    # Arguments
    parser.add_argument( '-cnt', dest='cnt_path', type=str, required=True,
                         help="Path to the cnt file generated by the sniffer tool" )
    parser.add_argument( '-cap', dest='cap_path', type=str, required=True,
                         help="Path to the cap file generated by the sniffer tool" )
    parser.add_argument( '-o', dest='out_path', type=str, default='stats.pickle',
                         help="Path to the output file (will be overwritten!)" )
    parser.add_argument( '-iip', '--ignore-ip', dest='ignored_ips',
                         nargs='+', type=str, default=[],
                         help="IP(v4/v6) addresses to ignore while resolving" )
    parser.add_argument( '-idom', '--ignore-domain', dest='ignored_domains',
                         nargs='+', type=str, default=[],
                         help="Domains to ignore while resolving" )
    parser.add_argument( '-ias', '--ignore-as', dest='ignored_as',
                         nargs='+', type=int, default=[],
                         help="AS numbers to ignore while resolving" )

    return parser

def process_cnt( cnt_path: str ):
    pattern = re.compile( "Counters at ([\d\-: ]+):.*IPv4Stats.*"
                          "v4_tcp_tx.*packets (\d+) bytes (\d+).*v4_tcp_rx.*packets (\d+) bytes (\d+).*"
                          "v4_udp_tx.*packets (\d+) bytes (\d+).*v4_udp_rx.*packets (\d+) bytes (\d+).*"
                          "IPv6Stats.*"
                          "v6_tcp_tx.*packets (\d+) bytes (\d+).*v6_tcp_rx.*packets (\d+) bytes (\d+).*"
                          "v6_udp_tx.*packets (\d+) bytes (\d+).*v6_udp_rx.*packets (\d+) bytes (\d+).*" )
    with open( cnt_path, 'r' ) as countfile:
        content = countfile.read()
    # Hacc
    content = content.replace( '\n\n', '###' )  # Add hacc markers
    content = content.replace( '\t', '' )       # Don't care about tabs
    content = content.replace( '\n', ' ' )      # One line per entry
    entries = content.split( '###' )            # Lord forgive me
    counts = {}
    # Process entries
    for entry in entries:
        matched = pattern.match( entry )
        if matched is not None:
            info = matched.groups()
            timestamp = datetime.strptime( info[ 0 ], '%Y-%m-%d %H:%M' )
            counts[ timestamp ] = { 'v4_tcp_txrx': ( int( info[ 1 ] ) + int( info[ 3 ] ),   int( info[ 2 ] ) + int( info[ 4 ] ) ),
                                    'v4_udp_txrx': ( int( info[ 5 ] ) + int( info[ 7 ] ),   int( info[ 6 ] ) + int( info[ 8 ] ) ),
                                    'v6_tcp_txrx': ( int( info[ 9 ] ) + int( info[ 11 ] ),  int( info[ 10 ] ) + int( info[ 12 ] ) ),
                                    'v6_udp_txrx': ( int( info[ 13 ] ) + int( info[ 15 ] ), int( info[ 14 ] ) + int( info[ 16 ] ) ) }
    timestamps = list( counts.keys() )
    delta_counts = deepcopy( counts )
    for i in range( len( timestamps ) - 1 ):
        prev = timestamps[ i ]
        cur = timestamps[ i+1 ]
        for field in ( 'v4_tcp_txrx', 'v4_udp_txrx', 'v6_tcp_txrx', 'v6_udp_txrx' ):
            delta_counts[ cur ][ field ] = ( counts[ cur ][ field ][ 0 ] - counts[ prev ][ field ][ 0 ],
                                             counts[ cur ][ field ][ 1 ] - counts[ prev ][ field ][ 1 ] )
    return ( timestamps, counts, delta_counts )

def get_cap_chunks( cap_path: str, timestamps: list[ datetime ] ):
    with open( cap_path, 'r' ) as capfile:
        lines = capfile.readlines()
    chunks = { end_timestamp: [] for end_timestamp in timestamps }
    timestamp_ptr = 0
    for line in lines:
        timestamp = datetime.strptime( line[ :16 ], '%Y-%m-%d %H:%M' )
        if timestamp > timestamps[ timestamp_ptr ]:
            timestamp_ptr += 1
        chunks[ timestamps[ timestamp_ptr ] ].append( line[ 17: ] )

    return chunks

def _resolve_domain( addr: str, ignored_domains: list[ str ] ):
    try:
        if ip_address( addr ).is_private:
            return None
        result = gethostbyaddr( addr )
        result_split = result[ 0 ].split( '.' )
        if len( result_split ) > 1: # Assuming there can be no useful domains without a '.', eg: 'ipv6-allnodes'
            result_domain = result_split[ -2 ] + '.' + result_split[ -1 ]   # 123.foo-bar.xyz.com -> xyz.com
            if result_domain not in ignored_domains:
                return result_domain
        return None
    except OSError:
        return None

def resolve( from_addr: str, to_addr: str,
             ignored_ips: list[ str ],
             domain_resolved_ips: dict[ str, Optional[ str ] ], domain_unresolved_ips: list[ str ], ignored_domains: list[ str ],
             as_db: pyasn, ignored_as: list[ int ] ):
    resolved_domain: str = None
    resolved_as: int = None

    # Resolve domain
    if from_addr in domain_resolved_ips:
        resolved_domain = domain_resolved_ips[ from_addr ]
    elif to_addr in domain_resolved_ips:
        resolved_domain = domain_resolved_ips[ to_addr ]
    else:
        for addr in ( from_addr, to_addr ):
            if ( addr not in ignored_ips ) and ( addr not in domain_unresolved_ips ):
                result = _resolve_domain( addr, ignored_domains )
                if result:
                    resolved_domain = result
                    domain_resolved_ips[ addr ] = resolved_domain
                else:
                    domain_unresolved_ips.append( addr )

    # Resolve AS
    for addr in ( from_addr, to_addr ):
        if ip_address( addr ).is_private or ( addr in ignored_ips ):
            continue
        ( asn, _ ) = as_db.lookup( addr )
        if ( asn is not None ) and ( asn not in ignored_as ):
            resolved_as = asn
    
    return ( resolved_domain, resolved_as )

def get_key( ip_version: str, transport: str ):
    assert ip_version in ( 'IP', 'IP6' ) and transport in ( 'UDP', 'tcp' )
    if ip_version == 'IP':
        if transport == 'UDP':
            return 'v4UDP'
        return 'v4TCP'
    else:
        if transport == 'UDP':
            return 'v6UDP'
        return 'v6TCP'

def process_cap( cap_path: str, timestamps: list[ datetime ],
                 ignored_ips: list, ignored_domains: list, ignored_as: list,
                 domain_resolved_ips: list, domain_unresolved_ips: list ):
    chunks: dict[ datetime, list[ str ] ] = get_cap_chunks( cap_path, timestamps )
    as_db = pyasn( 'as.db' )
    interval_stats = {}
    for timestamp, chunk in tqdm( chunks.items() ):
        interval_stats[ timestamp ] = { 'domains': { 'v4TCP': {}, 'v4UDP': {}, 'v6TCP': {}, 'v6UDP': {} },
                                        'as':      { 'v4TCP': {}, 'v4UDP': {}, 'v6TCP': {}, 'v6UDP': {} } }
        for line in chunk:
            ( ip_version, src_ip, src_port, dst_ip, dst_port, transport, count ) = line.split()
            ( domain, asn ) = resolve( src_ip, dst_ip,
                                       ignored_ips, domain_resolved_ips, domain_unresolved_ips,
                                       ignored_domains,
                                       as_db, ignored_as )
            key = get_key( ip_version, transport )
            if domain:
                interval_stats[ timestamp ][ 'domains' ][ key ][ domain ] = \
                    interval_stats[ timestamp ][ 'domains' ][ key ].get( domain, 0 ) + int( count )
            if asn:
                interval_stats[ timestamp ][ 'as' ][ key ][ asn ] = interval_stats[ timestamp ][ 'as' ][ key ].get( asn, 0 ) + int( count )
    
    return ( interval_stats, domain_resolved_ips, domain_unresolved_ips )

def main():
    # Parse command line arguments
    parser = get_parser()
    args = parser.parse_args()

    domain_resolved_ips = {}    # Cache of resolved IPs
    domain_unresolved_ips = []  # Tried resolving but failed
    # Try to load reverse DNS cache from existing stats pickle file
    try:
        with open( args.out_path, 'rb' ) as outfile:
            ( _, _, _, _, domain_resolved_ips, domain_unresolved_ips ) = pickle.load( outfile )
    except:
        pass

    ( timestamps, counts, delta_counts ) = process_cnt( args.cnt_path )
    ( interval_stats, domain_resolved_ips, domain_unresolved_ips ) = process_cap( args.cap_path, timestamps,
                                                                                  args.ignored_ips, args.ignored_domains, args.ignored_as,
                                                                                  domain_resolved_ips, domain_unresolved_ips )
    with open( args.out_path, 'wb' ) as outfile:
        pickle.dump( ( timestamps, counts, delta_counts, interval_stats, domain_resolved_ips, domain_unresolved_ips ),
                     outfile )

if __name__ == "__main__":
    main()